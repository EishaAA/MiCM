{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"5_Python_FileHandling.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyM/LYYRTCnaAc8LYnWUfAJF"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"t71pAdGqdZv8"},"source":["# Part 5: File Handling\n","\n","**NOTE: For the live demo, local file systems will be accessed and examples of the code below will be run locally. You will need to change the file paths before running much of the below code on your computer.**\n","\n","If you are running Python in the cloud using Google Collab to run a Jupytr notebook, then additional steps are necessary to access external files (not recommended for this portion of the workshop). You can access tutorials on how to do this here: https://towardsdatascience.com/3-ways-to-load-csv-files-into-colab-7c14fcbdcb92\n","\n","Python modules used in demo:\n","* `csv`\n","* `json`\n","* `pandas` (may require installation if never used)\n","* `Bio` (biopython)\n"]},{"cell_type":"markdown","metadata":{"id":"m0FgaX6Nf2qa"},"source":["---\n","\n","## Opening & closing a file\n","\n","To read from or write to a file, we must first open it. The `open()` function takes two main arguments - the filepath, and the mode in which to read your file (e.g. read, write, append) - and returns a file object. The most common mode arguments are as follows:\n","\n","*   `r` - **Read (default).** Opens a file for reading; error if file does not exist\n","*   `w` - **Write.** Opens a file for writing; creates the file if it does not exist (warning: this will overwrite an existing file!)\n","*   `a` - **Append.** Opens a file for appending; creates the file if it does not exist\n","\n","When you are finished with a file, it is important to close it to ensure computer resources are reallocated. This is done using the `close()` method.\n","\n","Below is an example of opening, then immediatlely closing a file."]},{"cell_type":"code","metadata":{"id":"Fr37ok64hT2s"},"source":["fp = open('/path/to.file.txt', 'r')     # open file in 'read' mode\n","fp.close()                              # close file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BCv5dgkQhXc1"},"source":["Instead of having to explicitly close a file, Python has a helpful way to automatically cleanup after yourself:"]},{"cell_type":"code","metadata":{"id":"oIT98126hYHA"},"source":["with open('/path/to/file.txt', 'r') as fp:\n","    # do some work with fp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"AxCgMQwthaN-"},"source":["This is equivalent to the following try-except block (where `close()` is always run):"]},{"cell_type":"code","metadata":{"id":"pcL4FLQ1hcvw"},"source":["try:\n","    fp = open('/path/to/file.txt', 'r')\n","    # do some work with fp\n","finally:\n","    fp.close()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_imuC4N5hhAW"},"source":["---\n","\n","## Reading Files\n","\n","The file object returned by `open()` has 3 methods to read data:\n","\n","*   `read()` - stores all the data into one text string; useful for small files where you want to do text manipulation on the entire file\n","*   `readlines()` - reads all the lines of the file at once, and returns a list of strings (each element corresponds to one line)\n","*   `readline()` - reads individual lines one at a time (increments); each time it is called, it reada another line. Great for handling very large files one line at a time\n","\n","Below is an example of reading a file line-by-line:"]},{"cell_type":"code","metadata":{"id":"kxTcZCN_hsEX"},"source":["with open('/path/to/file.txt', 'r') as fp:\n","    line = fp.readline()\n","    count = 0\n","    while line:\n","        count += 1\n","        print(\"[{}]: {}\".format(count, line.strip()))\n","        line = fp.readline()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jBXUxKPBhtRG"},"source":["We can do even better, by taking advantage of Python syntax to easily iterate through the file object, line-by-line:"]},{"cell_type":"code","metadata":{"id":"tONb7GXuhvRf"},"source":["with open('/path/to/file.txt', 'r') as fp:\n","    for count, line in enumerate(fp):\n","        print(\"[{}]: {}\".format(count, line.strip()))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WumBNzf6hy4g"},"source":["---\n","\n","## Writing files\n","\n","Writing files is quite straightforward in Python. We use the `open()` function as before, this time opening the file in write mode. We can then use the `write()` method to write strings to the file - each time it is called, another line is written to the file.\n","\n","Note that if a file does not already exist with the filepath and name, it will be automatically created. Similarly, a file with that name already exists, it will be overwritten (and the previous data lost).\n","\n","Below is a simple example of 10 lines to a file."]},{"cell_type":"code","metadata":{"id":"UiPNtJ71h-Sf"},"source":["with open('/path/to/outfile.txt', 'w') as fp:\n","    for i in range(10):\n","        fp.write(\"This is line {:.0f}\\n\".format(i))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2xRKqGiWiD5F"},"source":["---\n","\n","## Reading TSV and CSV files\n","\n","Datasets are often shared in one of the following file formats:\n","\n","* **CSV (Comma Separated Values)** - Highly compatible, and prevalent format. Not easily human readable.\n","* **TSV (Tab Separated Values)** - Easy to read for humans, easy to work with, and often more efficient for software. Generally more sound delimiters (as tabs rarely show-up in datasets, unlike commas).\n","\n","Remember that different file extensions do not affect the ability of your program to read its contents (e.g. using .txt for TSV files).\n","Below is an example of a function that can read TSV or CSV files line-by-line, simply by changing the delimiter you pass as an argument:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6MSSPHo9iVx9","executionInfo":{"status":"ok","timestamp":1614245627015,"user_tz":300,"elapsed":193,"user":{"displayName":"Eisha Ahmed","photoUrl":"","userId":"03679622835187765301"}},"outputId":"28999c7e-a9a3-443e-bd15-b83ef937ff28"},"source":["def readFile(filepath, sep):\n","    try:\n","        with open(filepath, 'r') as fp:\n","            for line in fp:\n","                rowArray = line.strip.split(sep)\n","                # do something with rowArray (e.g. print, save, populate objects etc.)\n","    except FileNotFoundError as e:\n","        print(\"Error: File not found.\")\n","    except OSError as e:\n","        print(\"System-related or IO error.\")\n","    except Exception as e:\n","        print(\"Sorry, can't read the file.\")\n","    return\n","\n","\n","# testing the function\n","readFile(\"myCSVdata.csv\", \",\")  # use a comma as the seperator argument (CSV)\n","readFile(\"myTSVdata.tsv\", \"\\t\")  # use a comma as the seperator argument (CSV)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Error: File not found.\n","Error: File not found.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Hzv-LONBiekE"},"source":["There are also both built-in and external tools to help read TSV and CSV files.\n","\n","Python has a built-in `csv` library, which helps both read and write from CSV files (can also read from TSV files, if you change the delimiter from `,` to `\\t`). Below is an example:"]},{"cell_type":"code","metadata":{"id":"1Fo60Id3inn7"},"source":["import csv\n","\n","with open('myfile.csv') as fp:\n","    csv_reader = csv.reader(fp, delimiter=',')\n","    lineCount = 0\n","    for rowArray in csv_reader:\n","        if line_count == 0:         # header row\n","            # do something with header row\n","            lineCount += 1\n","        else:\n","            # do something with rowArray\n","            lineCount += 1\n","\n","    print('Processed {} lines.'.format(lineCount))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fQX_aC11is3t"},"source":["Reading CSV and TSV files can also be done with external libraries like **pandas** (an excellent library for working with datasets in general), which reads and writes to and from \"pandas dataframe objects\".\n","\n","Here's the simplest example:"]},{"cell_type":"code","metadata":{"id":"LohTYfmWiuOt"},"source":["import pandas as pd\n","df = pd.read_csv('mydata.csv') # reading csv file into pandas dataframe object\n","print(df)\n","\n","df.to_csv('outfile.csv')    # writing pandas dataframe object to file"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6iEuRV-piwGl"},"source":["There are multiple additional arguments you can pass to the `read_csv()` method that can further specify things like the presence of a header row, index column, and separator (so you can also read tsv files).\n","\n","A full discussion of the Pandas library is beyond the scope of this workshop, however it is highly encouraged that you explore it afterwards if you are doing data analysis work: https://pandas.pydata.org/"]},{"cell_type":"markdown","metadata":{"id":"vq3EbrS1i8xM"},"source":["---\n","\n","## Working with FASTA files\n","\n","FASTA files - live CSV or TSV - contain plain text formatted data, and are used to represent nucleotide or peptide sequences. This file format is very common in bioinformatics and computational biology - you are likely to have come across this format, or worked with these files in the past if you are in biology.\n","\n","A sequence in FASTA format begins with a single-line description (preceded by '>'), followed by lines of sequence data. Files can contain a single sequence, or many thousands of sequences! Common extensions are `.fasta` and `.fa`.\n","\n","There are different ways of reading and handling FASTA-formatted data.\n","\n","One method is to simply use external libraries to read and process FASTA files. For example, here is an example using `SeqIO` Biopython:"]},{"cell_type":"code","metadata":{"id":"2yEsLCbDi7uU"},"source":["!pip install biopython # installing BioPython (for Google Collab)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"05NhXpUAjD88"},"source":["from Bio import SeqIO\n","\n","filenameIn = 'someFastaFile.fasta'\n","filenameOut = 'outputFastaFile.fasta'\n","\n","with open(filenameOut, 'w') as fp:\n","    for record in SeqIO.parse(open(filenameIn, mode='r'), 'fasta'):\n","        # do something (print or edit seq_record)\n","        print('SequenceID = '  + record.id)\n","        print('Seq = ' + record.seq + '\\n')\n","\n","        # write new fasta file\n","        r = SeqIO.write(record, fp, 'fasta')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DiOFpNQ4jLvc"},"source":["To install BioPython (an external library) on your machine, you can follow the instructions here: https://biopython.org/wiki/Download\n","\n","However, you can also create your own tools to read and process FASTA files, without having to rely on external libraries. Below is an example:"]},{"cell_type":"code","metadata":{"id":"uahxLjMUjLIf"},"source":["class FastaRecord:\n","    \"\"\"Class representing a FASTA record.\"\"\"\n","\n","    def __init__(self, description):\n","        \"\"\"Initialise an instance of the FastaRecord class.\"\"\"\n","        self.description = description.strip()\n","        self.sequences = []\n","\n","    def addSeqLine(self, sequence):\n","        \"\"\"Add a sequence line to the FastaRecord.\"\"\"\n","        self.sequences.append(sequence.strip())\n","\n","    def __repr__(self):\n","        \"\"\"Generate string representation of FastaRecord objects.\"\"\"\n","        lines = [self.description,]\n","        lines.extend(self.sequences)\n","        return '\\n'.join(lines)\n","\n","class FastaParser:\n","    \"\"\"Class for parsing FASTA files; populates FastaRecord objects.\"\"\"\n","\n","    def __init__(self, filepath):\n","        \"\"\"Initialise new instance of FastaParser.\"\"\"\n","        self.filepath = filepath\n","\n","    def __iter__(self):\n","        \"\"\"Yield FastaRecord instances.\"\"\"\n","        fastaObj = None\n","        with open(self.filepath, 'r') as f:\n","            for line in f:\n","                if line.startswith('>'):            # beginning of new fasta record\n","                    if fastaObj:\n","                        yield fastaObj              # release existing fasta record\n","                    fastaObj = FastaRecord(line)    # instantiate new fasta record\n","                else:\n","                    # add additional sequence line to fasta record\n","                    fastaObj.addSeqLine(line)\n","        yield fastaObj                              # release last fasta record\n","\n","\n","# let's look at an example of how we would use our parser\n","parser = FastaParser(\"someFastaFile.fa\")\n","for record in parser:\n","    print(record)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6jPzGRuMjUgI"},"source":["Experiment with the code above, or have a go at writing your own custom FASTA parser!"]},{"cell_type":"markdown","metadata":{"id":"zSTU79ZRjbBk"},"source":["---\n","\n","## Reading JSON files\n","\n","JSON (JavaScript Object Notation) is an open-standard, human-readable file format for data transfer. It is a very common format, and many programming languages (including Python) have libraries to generate and parse JSON files and formatted data. This format can be particularly useful for saving object attributes, or as simple configuration files.\n","\n","JSON files use the `.json` extention.\n","\n","Below is an example of JSON-formatted data:\n","\n","\n","```\n","{\n","    “firstname”: “Eisha”,\n","    ”lastname”: “Ahmed”,\n","    “isStudent”: true,\n","    ”favNumber”: 163,\n","    “phoneNumbers”: [\n","        {\n","            “type”: “home”,\n","            “number”: “514-123-4567”\n","        },\n","        {\n","            \"type”: “home”,\n","            “number”: “514-123-4567”\n","        }\n","    ]\n","}\n","```\n","\n","Looks a lot like a Python dictionary! Indeed, we can write Python objects like dictionaries and lists to json files by importing the `json` module. Similarly, we can read json files into a Python dictionary. See below for an example of reading and writing to a JSON file."]},{"cell_type":"code","metadata":{"id":"HHu2GxLrjgf3"},"source":["import json\n","\n","# here's an example of a nested dictionary\n","data = {\n","    \"firstname\": \"Eisha\",\n","    \"lastname\": \"Ahmed\",\n","    \"isStudent\": True,\n","    \"favNumber\": 163,\n","    \"phoneNumbers\": [\n","                     {\"type\": \"home\", \"number\": \"514-123-4567\"},\n","                     {\"type\": \"mobile\", \"number\": \"514-555-5555\"},\n","    ]\n","}\n","\n","# let's export it to a json file using json.dump()\n","with open(\"filename.json\", \"w\") as fp:\n","    json.dump(data, fp)\n","\n","# we can just as easily read a json file using json.load()\n","with open(\"filename.json\", \"r\") as fp2:\n","    data2 = json.load(fp2)\n","\n","print(data2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"M5-1ZtUzji9X"},"source":["What if we have a JSON formatted string? (e.g. text read directly from a file or another program) Easy! Just use `json.loads()`."]},{"cell_type":"code","metadata":{"id":"n6RT36WtjjzA"},"source":["import json\n","\n","dataString = \"\"\"\n","{\n","    \"firstname\": \"Eisha\",\n","    \"lastname\": \"Ahmed\",\n","    \"isStudent\": true,\n","    \"favNumber\": 163,\n","    \"phoneNumbers\": [\n","        {\"type\": \"home\", \"number\": \"514-123-4567\"},\n","        {\"type\": \"mobile\", \"number\": \"514-555-5555\"}\n","    ]\n","}\n","\"\"\"\n","\n","data3 = json.loads(dataString)\n","print(data3)\n","print(data3['favNumber'])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lhufi0QjjrTY"},"source":["This external reference contains a great tutorial on working with JSON formatted data in Python: https://realpython.com/python-json/"]}]}